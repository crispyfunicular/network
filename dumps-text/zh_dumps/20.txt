   #Home Recent Entries 45岁以后的人生 Pull Request 的命令行管理

   阮一峰的网络日志 » 首页 » 档案
   ____________________ 搜索
     * 上一篇：45岁以后的人生
     * 下一篇：Pull Reques

   分类：
     * 算法与数学

     * ⇐
     *  ⇒

神经网络入门

   作者： 阮一峰

   日期： 2017年7月13日

   眼下最热门的技术，绝对是人工智能。

   人工智能的底层模型是"神经网络"（neural
   network）。许多复杂的应用（比如模式识别、自动控制）和高级模型（比如深度学习）都基于它。学习人工智能，一定是从它开始。

   什么是神经网络呢？网上似乎缺乏通俗的解释。

   前两天，我读到 Michael Nielsen 的开源教材《神经网络与深度学习》（Neural Networks and Deep
   Learning），意外发现里面的解释非常好懂。下面，我就按照这本书，介绍什么是神经网络。

   这里我要感谢优达学城的赞助，本文结尾有他们的《前端开发（进阶）》课程的消息，欢迎关注。

一、感知器

   历史上，科学家一直希望模拟人的大脑，造出可以思考的机器。人为什么能够思考？科学家发现，原因在于人体的神经网络。

    1. 外部刺激通过神经末梢，转化为电信号，转导到神经细胞（又叫神经元）。
    2. 无数神经元构成神经中枢。
    3. 神经中枢综合各种信号，做出判断。
    4. 人体根据神经中枢的指令，对外部刺激做出反应。

   既然思考的基础是神经元，如果能够"人造神经元"（artificial
   neuron），就能组成人工神经网络，模拟思考。上个世纪六十年代，提出了最早的"人造神经元"模型，叫做"感知器"（perceptron），直到
   今天还在用。

   上图的圆圈就代表一个感知器。它接受多个输入（x1，x2，x3...），产生一个输出（output），好比神经末梢感受各种外部环境的变化，最后产
   生电信号。

   为了简化模型，我们约定每种输入只有两种可能：1 或
   0。如果所有输入都是1，表示各种条件都成立，输出就是1；如果所有输入都是0，表示条件都不成立，输出就是0。

二、感知器的例子

   下面来看一个例子。城里正在举办一年一度的游戏动漫展览，小明拿不定主意，周末要不要去参观。

   他决定考虑三个因素。

    1. 天气：周末是否晴天？
    2. 同伴：能否找到人一起去？
    3. 价格：门票是否可承受？

   这就构成一个感知器。上面三个因素就是外部输入，最后的决定就是感知器的输出。如果三个因素都是
   Yes（使用1表示），输出就是1（去参观）；如果都是 No（使用0表示），输出就是0（不去参观）。

三、权重和阈值

   看到这里，你肯定会问：如果某些因素成立，另一些因素不成立，输出是什么？比如，周末是好天气，门票也不贵，但是小明找不到同伴，他还要不要去参观呢？

   现实中，各种因素很少具有同等重要性：某些因素是决定性因素，另一些因素是次要因素。因此，可以给这些因素指定权重（weight），代表它们不同的重
   要性。

     * 天气：权重为8
     * 同伴：权重为4
     * 价格：权重为4

   上面的权重表示，天气是决定性因素，同伴和价格都是次要因素。

   如果三个因素都为1，它们乘以权重的总和就是 8 + 4 + 4 = 16。如果天气和价格因素为1，同伴因素为0，总和就变为 8 + 0 + 4
   = 12。

   这时，还需要指定一个阈值（threshold）。如果总和大于阈值，感知器输出1，否则输出0。假定阈值为8，那么 12 >
   8，小明决定去参观。阈值的高低代表了意愿的强烈，阈值越低就表示越想去，越高就越不想去。

   上面的决策过程，使用数学表达如下。

   上面公式中，x表示各种外部因素，w表示对应的权重。

四、决策模型

   单个的感知器构成了一个简单的决策模型，已经可以拿来用了。真实世界中，实际的决策模型则要复杂得多，是由多个感知器组成的多层网络。

   上图中，底层感知器接收外部输入，做出判断以后，再发出信号，作为上层感知器的输入，直至得到最后的结果。（注意：感知器的输出依然只有一个，但是可以
   发送给多个目标。）

   这张图里，信号都是单向的，即下层感知器的输出总是上层感知器的输入。现实中，有可能发生循环传递，即 A 传给 B，B 传给 C，C 又传给
   A，这称为"递归神经网络"（recurrent neural network），本文不涉及。

五、矢量化

   为了方便后面的讨论，需要对上面的模型进行一些数学处理。

     * 外部因素 x1、x2、x3 写成矢量 <x1, x2, x3>，简写为 x
     * 权重 w1、w2、w3 也写成矢量 (w1, w2, w3)，简写为 w
     * 定义运算 w⋅x = ∑ wx，即 w 和 x 的点运算，等于因素与权重的乘积之和
     * 定义 b 等于负的阈值 b = -threshold

   感知器模型就变成了下面这样。

六、神经网络的运作过程

   一个神经网络的搭建，需要满足三个条件。

     * 输入和输出
     * 权重（w）和阈值（b）
     * 多层感知器的结构

   也就是说，需要事先画出上面出现的那张图。

   其中，最困难的部分就是确定权重（w）和阈值（b）。目前为止，这两个值都是主观给出的，但现实中很难估计它们的值，必需有一种方法，可以找出答案。

   这种方法就是试错法。其他参数都不变，w（或b）的微小变动，记作Δw（或Δb），然后观察输出有什么变化。不断重复这个过程，直至得到对应最精确输出
   的那组w和b，就是我们要的值。这个过程称为模型的训练。

   因此，神经网络的运作过程如下。

    1. 确定输入和输出
    2. 找到一种或多种算法，可以从输入得到输出
    3. 找到一组已知答案的数据集，用来训练模型，估算w和b
    4. 一旦新的数据产生，输入模型，就可以得到结果，同时对w和b进行校正

   可以看到，整个过程需要海量计算。所以，神经网络直到最近这几年才有实用价值，而且一般的 CPU 还不行，要使用专门为机器学习定制的 GPU
   来计算。

七、神经网络的例子

   下面通过车牌自动识别的例子，来解释神经网络。

   所谓"车牌自动识别"，就是高速公路的探头拍下车牌照片，计算机识别出照片里的数字。

   这个例子里面，车牌照片就是输入，车牌号码就是输出，照片的清晰度可以设置权重（w）。然后，找到一种或多种图像比对算法，作为感知器。算法的得到结果
   是一个概率，比如75%的概率可以确定是数字1。这就需要设置一个阈值（b）（比如85%的可信度），低于这个门槛结果就无效。

   一组已经识别好的车牌照片，作为训练集数据，输入模型。不断调整各种参数，直至找到正确率最高的参数组合。以后拿到新照片，就可以直接给出结果了。

八、输出的连续性

   上面的模型有一个问题没有解决，按照假设，输出只有两种结果：0和1。但是，模型要求w或b的微小变化，会引发输出的变化。如果只输出0和1，未免也太
   不敏感了，无法保证训练的正确性，因此必须将"输出"改造成一个连续性函数。

   这就需要进行一点简单的数学改造。

   首先，将感知器的计算结果wx + b记为z。

z = wx + b

   然后，计算下面的式子，将结果记为σ(z)。

σ(z) = 1 / (1 + e^(-z))

   这是因为如果z趋向正无穷z → +∞（表示感知器强烈匹配），那么σ(z) → 1；如果z趋向负无穷z →
   -∞（表示感知器强烈不匹配），那么σ(z) → 0。也就是说，只要使用σ(z)当作输出结果，那么输出就会变成一个连续性函数。

   原来的输出曲线是下面这样。

   现在变成了这样。

   实际上，还可以证明Δσ满足下面的公式。

   即Δσ和Δw和Δb之间是线性关系，变化率是偏导数。这就有利于精确推算出w和b的值了。

   （正文完）

   =============================================

   下面是推广时间。

   前端开发是优达学城 Udacity
   的纳米学位课程，分成两个级别：入门班和进阶班。今年下半年的进阶班，今天（7月13日）开始报名了，感兴趣的朋友不要错过！

   本课程的重点是讲解如何应用 CSS 框架和 JavaScript
   框架，做出高性能、高可用性的产品，并且使用测试工具保证代码质量。学习过程中，学员必须完成以下课堂练习。

   [bg2017071219.jpg] [bg2017071220.jpg]

   [bg2017071221.jpg] [bg2017071222.jpg]

   该课程是纳米学位课程，学员提交的每一行代码都有导师 code review，并且每周可以预约导师一对一辅导，对于提高个人能力极有帮助。

   由于有真人 code review 环节，所以招生人数有限制，本期只有200个名额，目前已经预定了67个。点击这里了解详情，报名从速哦。

   （完）

文档信息

     * 版权声明：自由转载-非商用-非衍生-保持署名（创意共享3.0许可证）
     * 发表日期： 2017年7月13日

   netnut 数据抓取 IP 池
   netnut

相关文章

     * 2021.09.22: 俄罗斯总理的几何题
       9月1日是俄罗斯的知识节，因为这一天是各级学校的开学日，象征进入知识宝库的日子。
     * 2019.01.28: Prolog 语言入门教程
       Prolog 是一种与众不同的语言，不用来开发软件，专门解决逻辑问题。比如，"苏格拉底是人，人都会死，所以苏格拉底会死"这一类的问题。
     * 2018.09.05: 哈希碰撞与生日攻击
       一、哈希碰撞是什么？
       所谓哈希（hash），就是将不同的输入映射成独一无二的、固定长度的值（又称"哈希值"）。它是最常见的软件运算之一。
     * 2017.12.13: 图像与滤波
       我对图像处理一直很感兴趣，曾经写过好几篇博客（1，2，3，4）。

留言（85条）

   Ricky 说：

   阈值

   2017年7月13日 08:13 | # | 引用

   Ming 说：

   阈 打成了 阙

   2017年7月13日 08:31 | # | 引用

   徐 说：

   一峰，你的每一篇文章我都有阅读，写作风格浅显易懂，但有讲的透彻，非常难得，希望能看到你的更多分享，我们会一直支持你！

   2017年7月13日 08:39 | # | 引用

   阮一峰 说：

   @Ricky @Ming：

   谢谢指出，已经改正。

   2017年7月13日 08:47 | # | 引用

   JSK 说：

     历史上，科学家一直希望模拟人的大脑，造出可以思考的机器。人为什么能够思考？科学家发现，原因在于人体的神经网络。
     * 外部刺激通过神经末梢，转化为电信号，转导到神经细胞（又叫神经元）。
     * 无数神经元构成神经中枢。
     * 神经中枢综合各种信号，做出判断。
     * 人体根据神经中枢的指令，对外部刺激做出反应。

     既然思考的基础是神经元，如果能够"人造神经元"（artificial neuron），就能组成人工神经网络，模拟思考。…

   对比王垠的论述(http://www.yinwang.org/blog-cn/2017/04/23/ai)：

   人工智能的研究者们总是喜欢抬出“神经元”一类的名词来吓人，跟你说他们的算法是受了人脑神经元工作原理的启发。注意了，“启发”是一个非常模棱两可的
   词，由一个东西启发得来的结果，可以跟这个东西毫不相干。比如我也可以说，Yin 语言的设计是受了九 yin 真经的启发 :P

   世界上这么多 AI 研究者，有几个真的研究过人脑，解刨过人脑，拿它做过实验，或者读过脑科学的研究成果？最后你发现，几乎没有 AI
   研究者真正做过人脑或者认知科学的研究。著名的认知科学家 Douglas Hofstadter 早就在接受采访时指出，这帮所谓“AI
   专家”，对人脑和意识（mind）是怎么工作的，其实完全不感兴趣，也从来没有深入研究过，却号称要实现“通用人工智能”（Artificial
   General Intelligence, AGI），这就是为什么 AI 直到今天都只是一个虚无的梦想。

   2017年7月13日 09:19 | # | 引用

   ClayIdols 说：

   浅显易懂，拜谢

   2017年7月13日 09:37 | # | 引用

   zhoukekestar 说：

   推荐一个Deep
   learning的开源学习网站，https://github.com/exacity/deeplearningbook-chinese

   2017年7月13日 09:52 | # | 引用

   RyuGou 说：

   作为一个金融学专业的博士，您是如何在计算机领域呼风唤雨的

   2017年7月13日 10:16 | # | 引用

   www 说：

   这段没明白“阈值的高低代表了意愿的强烈，阈值越低就表示越想去，越高就越不想去。”
   阈值高低与想不想去是自己定义的还是有硬性规定？
   有没有看懂的楼友回答一下

   2017年7月13日 10:23 | # | 引用

   tonydong 说：

   一如既往的清晰明了

   2017年7月13日 11:25 | # | 引用

   soul 说：

引用www的发言：

     这段没明白“阈值的高低代表了意愿的强烈，阈值越低就表示越想去，越高就越不想去。”
     阈值高低与想不想去是自己定义的还是有硬性规定？
     有没有看懂的楼友回答一下

   这里的阈值是和上面说去漫展的例子结合起来的，整片文章超过一半都在谈阈值，因为目前是主观定义的，只能通过训练进行修正

   2017年7月13日 11:38 | # | 引用

   Asimov 说：

引用www的发言：

     这段没明白“阈值的高低代表了意愿的强烈，阈值越低就表示越想去，越高就越不想去。”
     阈值高低与想不想去是自己定义的还是有硬性规定？
     有没有看懂的楼友回答一下

   结合上面小明看漫展的例子，这里的阈值是一个量化小明是否去漫展的关键数字。

   我们将天气、价格和同伴这三个关键因素（X）分别赋予了不同的权重（W）：8、4、4，假设条件满足那么X=1，不满足则X=0，如果三个条件都满足，
   那么最终得分就是8+4+4=16，否则为其他W*X的值。

   但是只凭这一个值还是无法决定小明是否要去漫展，因为缺少一个比较因素，而这个“阈值”就是比较因素：我们假设阈值为10，如果W*X>10小明去漫展
   ，如果W*X<=10小明不去漫展。

   那么很明显这个阈值就代表了小明去漫展的欲望强度，如果阈值越低则得分越容易超过，则小明就越容易去漫展，或者相反。例如：如果阈值=2，那么天气、价
   格、同伴只要任意满足其中的一个条件，小明就会去漫展。

   阈值是神经网络中一个最难确定的因素之一，目前都是人工设定，然后通过大量的数据训练，通过对比阈值的变换和结果正确度的变化来确定精确的数量，因为这
   两个因素是密切相关的。

   2017年7月13日 13:25 | # | 引用

   annoy 说：

   新时代的逻辑学

   2017年7月13日 22:37 | # | 引用

   szpzs 说：

   赞！非常简单易懂。哈哈，我也神经网络入门了。

   2017年7月14日 10:46 | # | 引用

   timguole 说：

   图像识别，下各种棋类都不能算是什么“人工智能”。充其量就是死板的数学模型+超快的运算速度。

   2017年7月14日 11:09 | # | 引用

   哈哈 说：

引用timguole的发言：

     图像识别，下各种棋类都不能算是什么“人工智能”。充其量就是死板的数学模型+超快的运算速度。

   那啥是人工智能

   2017年7月14日 17:44 | # | 引用

   长安 说：

引用timguole的发言：

     图像识别，下各种棋类都不能算是什么“人工智能”。充其量就是死板的数学模型+超快的运算速度。

   人类也是一样的

   2017年7月14日 19:01 | # | 引用

   喵小哥 说：

   文中

     算法的得到结果是一个概率

   ：
   应该改为“算法得到的结果是一个概率”。

   2017年7月15日 07:01 | # | 引用

   CD 说：

   人工智能不应该是模仿人脑的，就像现在的飞机也不是模仿鸟的飞翔。

   2017年7月15日 14:50 | # | 引用

   付超 说：

   论重读高数的重要性。

   2017年7月17日 13:59 | # | 引用

   JinhaoPlus 说：

   @JSK：

   哈哈，毕竟生物学和计算机科学的交叉学者的出现真的是好难啊！

   2017年7月17日 20:12 | # | 引用

   刘同周 说：

   把人工智能跟人脑的神经结构扯在一起，真是一个巨大的骗局

   2017年7月17日 21:19 | # | 引用

   唐健 说：

引用刘同周的发言：

     把人工智能跟人脑的神经结构扯在一起，真是一个巨大的骗局

   多层次神经网络模型确实灵感来自于生物学

   2017年7月18日 18:56 | # | 引用

   Moon 说：

   真是浅显易懂

   2017年7月21日 17:52 | # | 引用

   faremax 说：

   这个感觉做几个 demo 还行，但是研究透了对数学要求好高。

   2017年7月22日 09:58 | # | 引用

   solus 说：

   原文：阈值的高低代表了意愿的强烈，阈值越低就表示越想去，越高就越不想去。

   疑惑：这里应该是说总分越高越想去，并不是阈值越高越想去。阈值是表征难度，阈值越高，越难去。

   2017年7月25日 10:08 | # | 引用

   modle 说：

   由此看来,AI是基于判断和决策的喽

   2017年7月26日 09:39 | # | 引用

   Yvan 说：

   @JSK：

   表示完全不能认同，人工智能的确有夸大的成分，但在很多领域它都开始崭露头角，如果如作者所说，人工智能不可能实现，那霍金、马斯克也不用担心人工智能
   的危害了。最终智能能不能实现的确不好判断，但是在很多方面它的确是有用的，无论是语音识别、图像识别还是自动驾驶。

   2017年8月 3日 10:35 | # | 引用

   周涛 说：

   我一直搞这个，还是您讲的浅显易懂，haha

   2017年8月 3日 17:23 | # | 引用

   sec 说：

   http://neuralnetworksanddeeplearning.com/chap1.html
   为什么跟这篇老外写的文章这么类似呢？

   2017年8月14日 12:41 | # | 引用

   盖饭 说：

引用JSK的发言：

     世界上这么多 AI 研究者，有几个真的研究过人脑，解刨过人脑，拿它做过实验，或者读过脑科学的研究成果？最后你发现，几乎没有 AI
     研究者真正做过人脑或者认知科学的研究。著名的认知科学家 Douglas Hofstadter 早就在接受采访时指出，这帮所谓“AI
     专家”，对人脑和意识（mind）是怎么工作的，其实完全不感兴趣，也从来没有深入研究过，却号称要实现“通用人工智能”（Artificial
     General Intelligence, AGI），这就是为什么 AI 直到今天都只是一个虚无的梦想。

   赞同。我最近开始研究心理学，发现很多心理学的模型可以借鉴到AI来

   2017年8月15日 14:33 | # | 引用

   dou3516 说：

引用solus的发言：

     原文：阈值的高低代表了意愿的强烈，阈值越低就表示越想去，越高就越不想去。

     疑惑：这里应该是说总分越高越想去，并不是阈值越高越想去。阈值是表征难度，阈值越高，越难去。

   从另外一个角度考虑，阈值是主观给定的，所以反映了意愿的强烈，但是负相关，阈值设高（主观不想去）代表意愿越难满足（客观越难去）。再换一个角度从概
   率上考虑，阈值的高低代表概率的低高，也即难度的高低，这也正如你所说。这种差异只是看待问题的角度不同，表述不同罢了。

   2017年8月22日 10:44 | # | 引用

   HYW 说：

引用sec的发言：

     http://neuralnetworksanddeeplearning.com/chap1.html
     为什么跟这篇老外写的文章这么类似呢？

   人家在文章开头就说了，是按照这篇文章来介绍的。发现好文拿来分享

   2017年8月22日 20:30 | # | 引用

   代飞 说：

   @JSK：

   跨界人才很厉害，但也很稀少，更多是需要合作啦，比如现在的写代码的有几个人见过客户？研究人脑的AI专家不多，但借鉴或者说的启发的不少，至于非要说
   启发的两者之间没有任何关系，那比如你能说今天吃饭的方式是借鉴了昨天便便的长度么？明白人一眼能看出这有毛线的启发关系

   2017年8月27日 21:13 | # | 引用

   Miwoy 说：

   我的神经网络与遗传算法是通过一本书了解的，叫《游戏编程中的人工智能技术》，我必须推荐这本书，作者用几乎小学生水平的数学知识讲解了人工智能，不希
   望这么好的书就此埋没。

   并且顺口一提的是，深度学习是不能解决人工智能问题的。

   2017年9月20日 14:32 | # | 引用

   姚屹晨 说：

   一直在奋力追赶，从未遇见，不曾想到会在不同的时间于Neural networks and deep
   learning相遇。从α教程、ES6、如何变得有思想、黑客于画家、未来世界的幸存者...一路同行。

   2017年11月 6日 10:54 | # | 引用

   坐井观天 说：

引用www的发言：

     这段没明白“阈值的高低代表了意愿的强烈，阈值越低就表示越想去，越高就越不想去。”
     阈值高低与想不想去是自己定义的还是有硬性规定？
     有没有看懂的楼友回答一下

   因为阈值越低，你前面计算的w和x的点积就越容易大于它，从而输出1，不知道这样理解正不正确

   2017年11月 9日 14:30 | # | 引用

   wu 说：

   重新深刻而清晰的学到 "权重" 和 "阈值" 的意义, 谢谢大师

   2017年11月23日 15:08 | # | 引用

   Ivan 说：

   赞，今天重新阅读一遍，还是有收获：
   1，之前不太理解输入还需要加一个偏置值b的原因，现在知道b的意义是负阈值
   2，为了让输出具有连续性的意义，对值域[-R,R]做了一次映射(0,1)，匹配概率上的意义

   2017年11月27日 14:59 | # | 引用

   夏幻 说：

   b是否是biases呢。。。如果是的话是否应该翻译成偏移呢？

   2017年12月18日 15:41 | # | 引用

   阿驹 说：

   《终极算法——机器学习和人工智能如何重塑世界》

   值得一看。评论里很多人的争论，包括 wangyin 的那些，都可以得到一定解释。

   2017年12月22日 17:45 | # | 引用

   希冀在天涯 说：

   简直了， 通俗易懂。

   2018年1月 5日 15:13 | # | 引用

   Lostboy船长 说：

   阮兄，看了你的这篇文章。深有体会，感激之情溢于言表。不知道是否能和你交个朋友，多请教下这块的知识。我对图像处理和深度学习有非常浓厚的兴趣。

   2018年1月26日 13:50 | # | 引用

   承影 说：

   感觉太好了，豁然开朗

   2018年2月13日 10:26 | # | 引用

   ddd 说：

   如果三个条件都满足，但是小明有惰性，不想去，因为他以前就是一个不太喜欢出去玩的人，那这个在神经网络中如何体现呢

   2018年3月19日 16:29 | # | 引用

   Tony 说：

引用ddd的发言：

     如果三个条件都满足，但是小明有惰性，不想去，因为他以前就是一个不太喜欢出去玩的人，那这个在神经网络中如何体现呢

   可能需再加一层网络来表示惰性。
   比如之前上一层的z值作为输入，惰性根据这个输入再输出一个值来决定最终去还是不去。

   2018年3月24日 22:50 | # | 引用

   Molly 说：

   浅显易懂，是不是可以理解为线性规划求解呢？

   2018年4月 3日 11:22 | # | 引用

   szm 说：

   阮老师，人工智能是算法的累加，和编程语言无关，我这么理解对吗？针对不同的领域，可以用不同的语言，但是实现起来效率就不一定了。。

   2018年4月28日 17:08 | # | 引用

   Hpp 说：

   写的超级棒的！因为建模比赛才了解的这些东西，感觉打开了新世纪大门，感谢阮老师

   2018年5月 6日 21:35 | # | 引用

   元 说：

   写的特别好，谢谢老师！

   2018年5月29日 09:48 | # | 引用

   菜鸟一号 说：

   一级棒，给刚入门的人看都能看懂，而且用sigmoid函数将离散的结果连续化，真的太巧妙了。

   2018年6月26日 15:37 | # | 引用

   干嘛都都都 说：

   @JSK：

   我觉得这位说的好，但是AI研究者不是不想研究人脑，实在是不好研究啊，你说找个活的研究还是死的研究啊，死了一点点解刨神经元研究，还是活着在脑子上
   插上无数管子研究呢？脑研究只要有突破，AI算个P啊，照葫芦画瓢而已。人工通用智能（这个顺序念才对）就是和人类智能达到一个原理但性能更好的地步，
   说的通俗一点，就是人造人。现在的人工智能还是把人类成熟的思想变成算法输入给程序，程序才工作。
   想说点别的。
   这个世界的规律不会因人的思维而改变，也不会因为机器的思维而改变，怕个鸟啊！怕孩子超过自己而不生孩子，傻不傻啊！孩子真正顶天立地的时候会在乎父母
   那点财产？把孩子教的愚昧无知才是自取灭亡。希望走在前面的人不要束手束脚，你做错了自会有人来惩罚你的，但是勇敢的尝试才是伟人之行。
   活在当下，活在当下，活在当下。

   2018年7月 7日 15:10 | # | 引用

   xinyuan 说：

   非常好懂，谢谢。

   2018年8月25日 10:20 | # | 引用

   asmfeng 说：

   写的真棒，谢谢老师

   2018年8月28日 17:06 | # | 引用

   一个无名小卒 说：

   阮老大不管你信不信，我已经从理论上设计出真正的人工智能。

   2018年9月 6日 23:58 | # | 引用

   Somnus 说：

   写得很好，会一直支持、学习。

   2018年10月30日 19:58 | # | 引用

   孙 说：

   人工智能的本质和程序模型有内核上的区别。按照你的算法 如果小明三条条件都符合 甚至按递归算法小明所有输出都是1
   那么我们可以说小明百分之一百会去漫展吗。当然不 所以现在多数ai算法都是伪算法 直觉是什么 意识是什么 思维是什么 这些东西我们自己都搞不清楚
   我举一个最简单的例子 我们抛一个硬币 我们可以说 抛硬币是概率事件 这时人脑接收一个信息 硬币不是正面就是反面 问题是
   你怎么知道这是一个概率事件 如果概率事件本身是一个确定事件 那么人脑在思考这个事件时是确定事件还是随机事件？

   2018年11月14日 21:03 | # | 引用

   侯伟 说：

   写的非常好，这下知道什么是神经网络了，谢谢分享！

   2018年11月17日 09:39 | # | 引用

   aaa 说：

   一篇文章全是广告了！

   2018年11月26日 18:49 | # | 引用

   Antares 说：

   @JSK：

   同意这个观点，我个人感觉两者的关系就仅仅是处理模式相似。

   甚至我个人觉得“神经元”概念更类似于程序里面的函数，都是输入->处理->输出的这个过程，神经网络就是结合海量的函数。

   2019年2月27日 17:33 | # | 引用

   Andy 说：

   您好，两个四输入的神经网络能否通过耦合成一个八输入的神经网络，从而在实现其预测功能的情况下解决训练数据库过大的情况。

   2019年3月11日 10:15 | # | 引用

   明王朝 说：

   深度好文

   2019年12月31日 16:09 | # | 引用

   小猫 说：

   感谢，浅显易懂，虽然一些数学上的公式没看懂，但整个原理都理解了，感谢大神！

   2020年4月23日 09:59 | # | 引用

   大毛公主 说：

   和老师上课的课件一起看的 比老师讲的好!小学鸡感谢您
   一定要继续更呀！

   2020年4月25日 18:43 | # | 引用

   夏康钊 说：

   一峰大佬，我甚至关于tcp/ip，引用了你的解释方式制作在了视频，很喜欢你的解释，也很感谢你的指导！

   2020年5月22日 12:33 | # | 引用

   Will Xiao 说：

   讲得太少了，不过瘾

   2020年9月 4日 17:17 | # | 引用

   Lijiahai 说：

   哇 真的浅显易懂

   2020年10月19日 16:17 | # | 引用

   Robert 说：

   看了好多文章，或云里雾里的，或总有一层窗户纸，阮老师的文章总能把握住重点一下子把窗户纸捅破

   2020年10月25日 12:05 | # | 引用

   Doria 说：

   还是阮老师的文章通俗易懂，看了十篇网文不如看这里一篇

   2020年12月 4日 15:14 | # | 引用

   丫丫 说：

   看了很多篇关于神经网络的介绍，还是这篇讲得好，浅显易懂，让我明白了什么是神经网络，强推！

   2021年1月23日 21:56 | # | 引用

   莫铭 说：

   写的超级好, 要是能看到整本书的整理版就好了.

   2021年3月29日 13:30 | # | 引用

   错错 说：

引用ddd的发言：

     如果三个条件都满足，但是小明有惰性，不想去，因为他以前就是一个不太喜欢出去玩的人，那这个在神经网络中如何体现呢

   阈值设定为16，这样就算三个条件都满足了也不会去

   2021年9月 9日 11:05 | # | 引用

   yuanwenyu 说：

   写的很棒，能否还沿着这个讲下去，期待神经网络相关内容的更新！

   2021年10月29日 11:21 | # | 引用

   yue 说：

   很清楚完整，感谢分享！

   2021年12月13日 23:16 | # | 引用

   Tintalle 说：

引用长安的发言：

     人类也是一样的

   如果权重可以瞬时发生剧烈的变动，那基本上可以认为该程序生成了意识。
   我们人类自幼进行的学习训练，在我看来可以是确定权重系数表的训练。但人在情绪激动的时候会自行改写这个权重系数表，目前机器没有类似情绪刺激的机制还
   无法完成此类操作。

   2022年5月 7日 12:45 | # | 引用

   eddyzhang 说：

   老师,原文中清晰度设置为权重“w”不是很理解，因为我是先看了卷积神经网络回过头来看您的文章，感觉w在卷积神经网络识别图像领域其实是卷积核而不是
   清晰度呀，不知道理解的对不对。

   2022年6月20日 17:16 | # | 引用

   Richard 说：

   最后面那段, 有些懵了, 没有看明白

   2022年7月 6日 15:46 | # | 引用

   littlesujin 说：

   读入图片后，首先是如何找到车牌部分的照片的？

   2023年4月26日 09:52 | # | 引用

   龙海 说：

引用Richard的发言：

     最后面那段, 有些懵了, 没有看明白

   确实是的，对没有基础的人来说，最后一段有点跳跃。

   2023年8月23日 07:55 | # | 引用

   Worthing 说：

   讲得浅显易懂，真棒！

   2023年12月12日 13:40 | # | 引用

   thy 说：

   初中九年级的信息科技中人工智能中就要学传统神经网络:线性回归问题 和卷积神经网络:图象法别 -----阮老师的文章对我学习很有帮助

   2024年1月 2日 21:25 | # | 引用

   Neo 说：

引用JSK的发言：

     对比王垠的论述(http://www.yinwang.org/blog-cn/2017/04/23/ai)：

     人工智能的研究者们总是喜欢抬出“神经元”一类的名词来吓人，跟你说他们的算法是受了人脑神经元工作原理的启发。注意了，“启发”是一个非常模棱
     两可的词，由一个东西启发得来的结果，可以跟这个东西毫不相干。比如我也可以说，Yin 语言的设计是受了九 yin 真经的启发 :P
     世界上这么多 AI 研究者，有几个真的研究过人脑，解刨过人脑，拿它做过实验，或者读过脑科学的研究成果？最后你发现，几乎没有 AI
     研究者真正做过人脑或者认知科学的研究。著名的认知科学家 Douglas Hofstadter 早就在接受采访时指出，这帮所谓“AI
     专家”，对人脑和意识（mind）是怎么工作的，其实完全不感兴趣，也从来没有深入研究过，却号称要实现“通用人工智能”（Artificial
     General Intelligence, AGI），这就是为什么 AI 直到今天都只是一个虚无的梦想。

   今天是2024年5月22日，OpenAI此前宣称AGI在未来5-10年完成。科技进步超乎你我的想象。

   2024年5月22日 15:45 | # | 引用

   wxdlong 说：

   这真的是一篇2017年的教程? 大神的感知领先我十年啊

   2024年8月14日 09:38 | # | 引用

   loveyond 说：

引用CD的发言：

     人工智能不应该是模仿人脑的，就像现在的飞机也不是模仿鸟的飞翔。

   那是因为人类想模仿却无法模仿。现代飞机的样子其实是无奈之举，以人类目前拥有的科技水平，是无法制造出像鸟或者昆虫之类的飞行模式所需要的材料

   2024年8月16日 14:54 | # | 引用

   Bill 说：

   车牌的例子权重设置不是很明白， 为什么把照片清晰度设置为w， 那清晰度怎么判断的？ 是人工输入？

   2024年12月18日 12:26 | # | 引用

我要发表看法

   您的留言 （HTML标签部分可用）


   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________
   __________________________________________________

   您的大名：

   ______________________________ «-必填

   电子邮件：

   ______________________________ «-必填，不公开

   个人网址：

   ______________________________ «-我信任你，不会填写广告链接

   记住个人信息？ [ ]
   [ ]

   正在发表您的评论，请稍候

   ___ ______________________________________________

   发表 «- 点击按钮

   微信扫描

   Weibo | Twitter | GitHub

   Email: [email protected]
