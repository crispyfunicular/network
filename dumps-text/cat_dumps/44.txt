   #Modifica Viquipèdia (ca) Canal de sindicació Atom Viquipèdia

   Vés al contingut

   [ ] Menú principal
   Menú principal
   (BUTTON) mou a la barra lateral (BUTTON) amaga
   Navegació
     * Portada
     * Article a l'atzar
     * Articles de qualitat
     * Pàgines especials

   Comunitat
     * Portal viquipedista
     * Agenda d'actes
     * Canvis recents
     * La taverna
     * Contacte
     * Xat
     * Ajuda

   Viquipèdia l'Enciclopèdia Lliure
   Cerca
   ____________________
   (BUTTON) Cerca

   [ ] Aparença

     * Donatius
     * Crea un compte
     * Inicia la sessió

   [ ] Eines personals
     * Donatius
     * Crea un compte
     * Inicia la sessió

Contingut

   (BUTTON) mou a la barra lateral (BUTTON) amaga
     * Inici
     * 1 Visió general
     * 2 Història
     * 3 Intel·ligència artificial
     * 4 Aplicacions
     * 5 Neurociències
       (BUTTON) Commuta la subsecció Neurociències
          + 5.1 Tipus de models
          + 5.2 Connectivitat
     * 6 Crítica
     * 7 Millores recents
     * 8 Vegeu també
     * 9 Referències
     * 10 Enllaços externs

   [ ] Commuta la taula de continguts.

Xarxa neuronal

   [ ] 22 llengües
     * Afrikaans
     * العربية
     * English
     * فارسی
     * Galego
     * Հայերեն
     * Bahasa Indonesia
     * 한국어
     * Ligure
     * മലയാളം
     * Nederlands
     * Português
     * Slovenščina
     * Српски / srpski
     * தமிழ்
     * ไทย
     * Türkçe
     * Українська
     * Tiếng Việt
     * 中文
     * 粵語
     * IsiZulu

   Modifica els enllaços

     * Pàgina
     * Discussió

   [ ] català

     * Mostra
     * Modifica
     * Mostra l'historial

   [ ] Eines
   Eines
   (BUTTON) mou a la barra lateral (BUTTON) amaga
   Accions
     * Mostra
     * Modifica
     * Mostra l'historial

   General
     * Què hi enllaça
     * Canvis relacionats
     * Enllaç permanent
     * Informació de la pàgina
     * Citau aquest article
     * Obtén una URL abreujada
     * Descarrega el codi QR

   Imprimeix/exporta
     * Crea un llibre
     * Baixa com a PDF
     * Versió per a impressora

   En altres projectes
     * Element a Wikidata

   Aparença
   (BUTTON) mou a la barra lateral (BUTTON) amaga
   De la Viquipèdia, l'enciclopèdia lliure
   Per a altres significats, vegeu «xarxa neuronal artificial».
   No s'ha de confondre amb circuit neuronal.
   [langca-250px-Neural_network_example.svg.png] Vista simplificada d'una
   xarxa neuronal artificial avançada

   Una xarxa neuronal és una xarxa o circuit de neurones, o en un sentit
   modern, una xarxa neuronal artificial, composta de neurones o nodes
   artificials.^[1] Així, una xarxa neuronal és una xarxa neuronal
   biològica, formada per neurones biològiques reals, o una xarxa neuronal
   artificial, per resoldre problemes d'intel·ligència artificial (IA).
   Les connexions de la neurona biològica es modelen com a pesos. Un pes
   positiu reflecteix una connexió excitadora, mentre que els valors
   negatius signifiquen connexions inhibidores. Totes les entrades es
   modifiquen per un pes i es sumen. Aquesta activitat es coneix com una
   combinació lineal. Finalment, una funció d'activació controla
   l'amplitud de la sortida. Per exemple, un rang acceptable de sortida
   sol estar entre 0 i 1, o bé podria ser -1 i 1.

   Aquestes xarxes artificials es poden utilitzar per a models predictius,
   control adaptatiu i aplicacions on es poden entrenar mitjançant un
   conjunt de dades. L'autoaprenentatge resultant de l'experiència es pot
   produir a les xarxes, que poden derivar conclusions d'un conjunt
   d'informació complexa i aparentment no relacionada.^[2]

Visió general

   [modifica]

   Una xarxa neuronal biològica està composta per un grup de neurones
   connectades químicament o associades funcionalment. Una sola neurona
   pot estar connectada a moltes altres neurones i el nombre total de
   neurones i connexions en una xarxa pot ser extens. Les connexions,
   anomenades sinapsis, generalment es formen des d'axons fins a
   dendrites, tot i que són possibles sinapsis dendrodendrítiques^[3] A
   part de la senyalització elèctrica, hi ha altres formes de
   senyalització que sorgeixen de la difusió del neurotransmissor.

   La intel·ligència artificial, el modelatge cognitiu i les xarxes
   neuronals són paradigmes de processament d'informació inspirats en la
   forma en què els sistemes neuronals biològics processen les dades. La
   intel·ligència artificial i el modelatge cognitiu intenten simular
   algunes propietats de les xarxes neuronals biològiques. En el camp de
   la intel·ligència artificial, les xarxes neuronals artificials s'han
   aplicat amb èxit al reconeixement de veu, a l'anàlisi d'imatges i al
   control adaptatiu, per tal de construir agents de programari (en
   ordinadors i videojocs) o robots autònoms .

   Històricament, els ordinadors digitals van evolucionar a partir del
   model von Neumann i funcionen mitjançant l'execució d'instruccions
   explícites mitjançant l'accés a la memòria per part de diversos
   processadors. D'altra banda, els orígens de les xarxes neuronals es
   basen en esforços per modelar el processament d'informació en sistemes
   biològics. A diferència del model de von Neumann, la informàtica de
   xarxes neuronals no separa memòria i processament.

   La teoria de xarxes neuronals ha servit tant per identificar millor el
   funcionament de les neurones del cervell com per proporcionar la base
   per als esforços per crear intel·ligència artificial.

Història

   [modifica]

   La base teòrica preliminar per a les xarxes neuronals contemporànies va
   ser proposada independentment per Alexander Bain^[4] (1873) i William
   James^[5] (1890). En el seu treball, tant els pensaments com
   l'activitat corporal resultaven de les interaccions entre neurones del
   cervell.
   [250px-Forest_of_synthetic_pyramidal_dendrites_grown_using_Cajal%27s_la
   ws_of_neuronal_branching.png] Simulació per ordinador de l'arquitectura
   de ramificació de les dendrites de les neurones piramidals.^[6]

   Per a Bain,^[4] cada activitat conduïa al disparament d'un determinat
   conjunt de neurones. Quan es repetien les activitats, les connexions
   entre aquestes neurones s'enfortien. Segons la seva teoria, aquesta
   repetició va ser la que va conduir a la formació de la memòria. La
   comunitat científica general de l'època era escèptica amb la perquè
   requeria el que semblava ser un nombre desmesurat de connexions
   neuronals dins del cervell. Ara és evident que el cervell és
   extremadament complex i que el mateix "cablejat" cerebral pot gestionar
   múltiples problemes i entrades.

   La^[5] era similar a la de Bain,^[4] no obstant això, va suggerir que
   els records i les accions resultaven del corrent elèctric que circulava
   entre les neurones del cervell. El seu model, en centrar-se en el flux
   de corrents elèctrics, no requeria connexions neuronals individuals per
   a cada memòria o acció.

   CS Sherrington^[7] (1898) va dur a terme experiments per provar la
   teoria de James. Corria corrents elèctrics per les medul·les espinales
   de les rates. No obstant això, en lloc de demostrar un augment del
   corrent elèctric tal com va projectar James, Sherrington va trobar que
   la intensitat del corrent elèctric disminuïa a mesura que les proves
   continuaven al llarg del temps. És important destacar que aquest
   treball va conduir al descobriment del concepte d' habituació .

   McCulloch i Pitts^[8] (1943) van crear un model computacional per a
   xarxes neuronals basat en matemàtiques i algorismes. Aquest model
   l'anomenaven lògica llindar. El model va obrir el camí perquè la
   investigació de xarxes neuronals es dividís en dos enfocaments
   diferents. Un enfocament es va centrar en els processos biològics del
   cervell i l'altre es va centrar en l'aplicació de xarxes neuronals a la
   intel·ligència artificial.

   A finals dels anys 40, el psicòleg Donald Hebb^[9] crear una hipòtesi
   d'aprenentatge basada en el mecanisme de plasticitat neuronal que ara
   es coneix com a aprenentatge Hebbian. L'aprenentatge Hebbian es
   considera una regla d'aprenentatge no supervisada “típica” i les seves
   variants posteriors van ser els primers models de potenciació a llarg
   termini. Aquestes idees van començar a aplicar-se als models
   computacionals el 1948 amb les màquines de tipus B de Turing .

   Farley i Clark^[10] (1954) van utilitzar primer màquines
   computacionals, després anomenades calculadores, per simular una xarxa
   Hebbian al MIT. Altres màquines computacionals de xarxes neuronals van
   ser creades per Rochester, Holland, Habit i Duda^[11] (1956).

   Rosenblatt^[12] (1958) va crear el perceptron, un algorisme per al
   reconeixement de patrons basat en una xarxa informàtica d'aprenentatge
   de dues capes mitjançant una simple suma i resta. Amb la notació
   matemàtica, Rosenblatt també va descriure circuits no al perceptró
   bàsic, com l'exclusiu-o circuit, un circuit el càlcul matemàtic del
   qual no es va poder processar fins després que l'algorisme de
   propagació posterior fos creat per Werbos^[13] (1975).

   La investigació sobre xarxes neuronals es va estancar després de la
   publicació de la investigació sobre aprenentatge automàtic de Marvin
   Minsky i Seymour Papert^[14] (1969). Van descobrir dos problemes clau
   amb les màquines computacionals que processaven xarxes neuronals. El
   primer problema va ser que les xarxes neuronals d'una sola capa eren
   incapaces de processar l'exclusiu o el circuit. El segon problema
   significatiu va ser que els ordinadors no eren prou sofisticats per
   manejar de manera efectiva el temps de llarga durada requerit per les
   grans xarxes neuronals. La investigació de xarxes neuronals es va
   desaccelerar fins que els ordinadors van aconseguir una major potència
   de processament. També va ser clau en els avanços posteriors
   l'algorisme de propagació posterior que va resoldre efectivament
   l'exclusiu o problema (Werbos 1975).^[13]

   El processament distribuït en paral·lel de mitjan anys vuitanta es va
   popularitzar amb el nom de connexionisme. El text de Rumelhart i
   McClelland^[15] (1986) va proporcionar una exposició completa sobre
   l'ús del connexionisme en ordinadors per simular processos neuronals.

   Les xarxes neuronals, tal com s'utilitza en intel·ligència artificial,
   tradicionalment s'han vist com models simplificats de processament
   neuronal al cervell, tot i que es discuteix la relació entre aquest
   model i l'arquitectura biològica cerebral, ja que no és clar fins a
   quin punt les xarxes neuronals artificials reflecteixen el cervell
   funció.^[16]

Intel·ligència artificial

   [modifica]

   Una xarxa neuronal (NN), en el cas de les neurones artificials
   anomenades xarxa neuronal artificial (ANN) o xarxa neuronal simulada
   (SNN), és un grup interconnectat de neurones naturals o artificials que
   utilitza un model matemàtic o computacional per al processament de la
   informació basat en un enfocament connexionalista de la computació. En
   la majoria dels casos, un ANN és un sistema adaptatiu que canvia la
   seva estructura en funció de la informació interna o externa que flueix
   a través de la xarxa.

   En termes més pràctics, les xarxes neuronals són eines de modelatge de
   dades estadístiques no lineals o eines de presa de decisions. Es poden
   utilitzar per modelar relacions complexes entre entrades i sortides o
   per trobar patrons en les dades.

   Una xarxa neuronal artificial implica una xarxa d'elements de
   processament senzills (neurones artificials) que poden presentar un
   comportament global complex, determinat per les connexions entre els
   elements de processament i els paràmetres dels elements. Les neurones
   artificials van ser proposades per primera vegada el 1943 per Warren
   McCulloch, neurofisiòleg, i Walter Pitts, lògic, que va col·laborar per
   primera vegada a la Universitat de Chicago.^[17]

   Un tipus clàssic de xarxa neuronal artificial és la xarxa Hopfield
   recurrent.

   El concepte de xarxa neuronal sembla haver estat proposat per primera
   vegada per Alan Turing en el seu article de 1948, Intelligent
   Machinery, en el qual les anomenava "màquines no organitzades de tipus
   B".^[18]

   La utilitat dels models de xarxes neuronals artificials rau en el fet
   que es poden utilitzar per inferir una funció a partir d'observacions i
   també per utilitzar-la. Les xarxes neuronals no supervisades també es
   poden utilitzar per aprendre representacions de l'entrada que capturen
   les característiques destacades de la distribució d'entrada, per
   exemple, vegeu la màquina de Boltzmann (1983) i, més recentment,
   algorismes d'aprenentatge profund, que implícitament poden aprendre la
   funció de distribució de la dades observades. L'aprenentatge en xarxes
   neuronals és particularment útil en aplicacions on la complexitat de
   les dades o tasques fa que el disseny d'aquestes funcions a mà no sigui
   pràctic.

Aplicacions

   [modifica]

   Les xarxes neuronals es poden utilitzar en diferents camps. Les tasques
   a les quals s'apliquen les xarxes neuronals artificials tendeixen a
   incloure's en les grans categories següents:
     * Aproximació de funcions o anàlisi de regressió, inclosa la
       predicció i modelització de sèries temporals.
     * Classificació, inclòs el reconeixement de patrons i seqüències,
       detecció de novetats i presa de decisions seqüencials.
     * Processament de dades, incloent filtratge, agrupació, separació de
       senyals cecs i compressió.

   Les àrees d'aplicació de les ANN inclouen identificació i control de
   sistemes no lineals^[19] (control de vehicles, control de processos),
   joc i presa de decisions (backgammon, escacs, carreres), reconeixement
   de patrons (sistemes de radar, identificació de rostres, reconeixement
   d'objectes), reconeixement de seqüències (gest, veu, reconeixement de
   text escrit a mà), diagnòstic mèdic, aplicacions financeres, mineria de
   dades (o descobriment de coneixement en bases de dades, "KDD"),
   visualització i filtratge de correu brossa de correu electrònic. Per
   exemple, és possible crear un perfil semàntic dels interessos de
   l'usuari que sorgeixi a partir d'imatges entrenades per al
   reconeixement d'objectes.^[20]

Neurociències

   [modifica]

   La neurociència teòrica i computacional és el camp relacionat amb
   l'anàlisi i el modelatge computacional de sistemes neuronals biològics.
   Atès que els sistemes neuronals estan íntimament relacionats amb els
   processos i el comportament cognitius, el camp està estretament
   relacionat amb la modelització cognitiva i conductual.

   L'objectiu del camp és crear models de sistemes neuronals biològics per
   entendre com funcionen els sistemes biològics. Per obtenir aquesta
   comprensió, els neurocientífics s'esforcen per establir un vincle entre
   processos biològics observats (dades), mecanismes biològicament
   plausibles per al processament i l'aprenentatge neuronal (models de
   xarxes neuronals biològiques) i teoria (teoria de l'aprenentatge
   estadístic i teoria de la informació).

Tipus de models

   [modifica]

   S'utilitzen molts models; definits a diferents nivells d'abstracció i
   modelant diferents aspectes dels sistemes neuronals. Van des de models
   de comportament a curt termini de neurones individuals, passant per
   models de dinàmica de circuits neuronals derivats de les interaccions
   entre neurones individuals, fins a models de comportament derivats de
   mòduls neuronals abstractes que representen subsistemes complets.
   Aquests inclouen models de plasticitat a llarg i curt termini dels
   sistemes neuronals i la seva relació amb l'aprenentatge i la memòria,
   des de la neurona individual fins al nivell del sistema.

Connectivitat

   [modifica]

   A l'agost de 2020, els científics van informar que les connexions
   bidireccionals, o les connexions de retroalimentació adequades, poden
   accelerar i millorar la comunicació entre les xarxes neuronals modulars
   de l'escorça cerebral del cervell i reduir el llindar per a una
   comunicació reeixida. Van demostrar que afegir connexions de
   retroalimentació entre un parell de ressonància pot donar suport a la
   propagació amb èxit d'un sol paquet d'impulsos a tota la
   xarxa.^[21]^[22]

Crítica

   [modifica]

   Una crítica habitual a les xarxes neuronals, particularment en
   robòtica, és que requereixen una gran diversitat de mostres
   d'entrenament per al funcionament del món real. Això no és d'estranyar,
   ja que qualsevol màquina d'aprenentatge necessita exemples
   representatius suficients per captar l'estructura subjacent que li
   permet generalitzar-se a casos nous. Dean Pomerleau, en la seva
   investigació presentada a l'article "Formació basada en el coneixement
   de xarxes neuronals artificials per a la conducció autònoma de robots",
   utilitza una xarxa neuronal per entrenar un vehicle robotitzat per
   conduir per diversos tipus de carreteres (carril simple, carril
   múltiple, terra), etc.). Una gran part de la seva investigació es
   dedica a (1) extrapolar múltiples escenaris d'entrenament a partir
   d'una única experiència d'entrenament i (2) a preservar la diversitat
   formativa passada perquè el sistema no es sobreentreni (si, per
   exemple, es presenta amb una sèrie de girs a la dreta: no s'ha
   d'aprendre a girar sempre a la dreta). Aquests problemes són habituals
   a les xarxes neuronals que han de decidir-se entre una àmplia varietat
   de respostes, però es poden tractar de diverses maneres, per exemple
   barrejant els exemples d'entrenament a l'atzar, mitjançant un algorisme
   d'optimització numèrica que no fa massa passos quan canviant les
   connexions de xarxa seguint un exemple o agrupant exemples en els
   anomenats mini-lots.

   AK Dewdney, antic columnista de Scientific American, va escriure el
   1997: "Tot i que les xarxes neuronals resolen alguns problemes de
   joguines, els seus poders de càlcul són tan limitats que em sorprèn que
   qualsevol persona els prengui seriosament com a eina general de
   resolució de problemes" (Dewdney, pàg. 82).

   Els arguments per a la posició de Dewdney són que per implementar
   xarxes neuronals de programari grans i efectives, cal dedicar molts
   recursos de processament i emmagatzematge. Tot i que el cervell té un
   maquinari adaptat a la tasca de processar senyals mitjançant un gràfic
   de neurones, simular fins i tot una forma més simplificada de la
   tecnologia Von Neumann pot obligar un dissenyador de xarxes neuronals a
   omplir molts milions de files de bases de dades per a les seves
   connexions, que poden consumir grans quantitats. de capacitat
   d'emmagatzematge de dades i memòria de l'ordinador. A més, el
   dissenyador de sistemes de xarxes neuronals sovint haurà de simular la
   transmissió de senyals a través de moltes d'aquestes connexions i les
   seves neurones associades, que sovint s'han d'aparellar amb increïbles
   quantitats de potència i temps de processament de la CPU. Tot i que les
   xarxes neuronals solen produir programes eficaços, massa sovint ho fan
   a costa d' eficiència (solen consumir una quantitat considerable de
   temps i diners).

   Els arguments contra la posició de Dewdney són que les xarxes neuronals
   s'han utilitzat amb èxit per resoldre moltes tasques complexes i
   diverses, com ara avions que volen de forma autònoma.^[23]

   L'escriptor tecnològic Roger Bridgman va comentar les declaracions de
   Dewdney sobre les xarxes neuronals:

     Les xarxes neuronals, per exemple, es troben al moll no només perquè
     han estat difoses fins al cel alt (què no?), Sinó també perquè
     podríeu crear una xarxa d'èxit sense entendre com funcionava: el
     grup de números que captura el comportament seria, amb tota
     probabilitat, "una taula opaca i il·legible ... sense valor com a
     recurs científic". Malgrat la seva emfàtica afirmació que la ciència
     no és tecnologia, Dewdney sembla que acapara les xarxes neuronals
     com a mala ciència quan la majoria dels que les dissenyen només
     intenten ser bons enginyers. Una taula il·legible que una màquina
     útil podria llegir encara valdria la pena.^[24]

   Tot i que és cert que analitzar el que ha après una xarxa neuronal
   artificial és difícil, és molt més fàcil fer-ho que analitzar el que ha
   après una xarxa neuronal biològica. A més, l'èmfasi recent en
   l'explicabilitat de la IA ha contribuït al desenvolupament de mètodes,
   sobretot els basats en mecanismes d'atenció, per visualitzar i explicar
   les xarxes neuronals apreses. A més, els investigadors implicats en
   l'exploració d'algoritmes d'aprenentatge per a xarxes neuronals van
   descobrint progressivament principis genèrics que permeten que una
   màquina d'aprenentatge tingui èxit. Per exemple, Bengio i LeCun (2007)
   van escriure un article sobre l'aprenentatge local enfront de
   l'aprenentatge no local, així com sobre l'arquitectura superficial i
   profunda.^[25]

   Algunes altres crítiques van venir dels creients dels models híbrids
   (combinant xarxes neuronals i enfocaments simbòlics). Defensen la
   barreja d'aquests dos enfocaments i creuen que els models híbrids poden
   captar millor els mecanismes de la ment humana (Sun i Bookman,
   1990).^[Cal citació completa]

Millores recents

   [modifica]

   Tot i que inicialment la investigació s'havia ocupat principalment de
   les característiques elèctriques de les neurones, una part especialment
   important de la investigació dels darrers anys ha estat l'exploració
   del paper de neuromoduladors com la dopamina, l'acetilcolina i la
   serotonina en el comportament i l'aprenentatge.

   Els models biofísics, com la teoria BCM, han estat importants per
   entendre els mecanismes de plasticitat sinàptica i han tingut
   aplicacions tant en informàtica com en neurociències. La investigació
   està en curs per entendre els algoritmes computacionals utilitzats al
   cervell, amb algunes evidències biològiques recents sobre xarxes de
   bases radials i la propagació posterior neuronal com a mecanismes per
   al processament de dades.

   S'han creat dispositius computacionals en CMOS tant per a la simulació
   biofísica com per a la informàtica neuromorfa. Els esforços més recents
   mostren una promesa per a la creació de nanodispositius per a anàlisis
   i convolució de components principals a gran escala.^[26] Si tenen
   èxit, aquests esforços podrien iniciar una nova era de la computació
   neuronal que és un pas més enllà de la informàtica digital,^[27] perquè
   depèn de l'aprenentatge més que de la programació i perquè és
   fonamentalment analògica en lloc de digital, tot i que les primeres
   instàncies poden de fet estar amb dispositius digitals CMOS.

   Entre el 2009 i el 2012, les xarxes neuronals recurrents i les xarxes
   neuronals avançades profundes desenvolupades al grup de recerca de
   Jürgen Schmidhuber al suís AI Lab IDSIA han guanyat vuit concursos
   internacionals de reconeixement de patrons i aprenentatge
   automàtic.^[28] Per exemple, la memòria multidimensional a curt termini
   (LSTM)^[29]^[30] guanyar tres concursos de reconeixement d'escriptura a
   mà a la Conferència Internacional d'Anàlisi i Reconeixement de
   Documents de 2009 (ICDAR), sense cap coneixement previ sobre els tres
   idiomes diferents ser après.

   Variants de l'algorisme de propagació posterior, així com mètodes no
   supervisats per Geoff Hinton i col·legues de la Universitat de Toronto,
   es poden utilitzar per entrenar arquitectures neuronals profundes i
   altament no lineals,^[31] similars al Neocognitron de 1980 de Kunihiko
   Fukushima,^[32] i l '"arquitectura estàndard de la visió",^[33]
   inspirada en les cèl·lules simples i complexes identificades per David
   H. Hubel i Torsten Wiesel a l'escorça visual primària.

   També s'han introduït funcions de bases radials i xarxes d'onetes. Es
   pot demostrar que ofereixen les millors propietats d'aproximació i
   s'han aplicat en aplicacions d'identificació i classificació de
   sistemes no lineals.^[19]

   Les xarxes avançades d'aprenentatge profund alternen capes
   convolucionals i capes d'agrupació màxima, superades per diverses capes
   de classificació pura. Les implementacions ràpides basades en GPU
   d'aquest enfocament han guanyat diversos concursos de reconeixement de
   patrons, inclòs el concurs de reconeixement de senyals de trànsit IJCNN
   2011^[34] i el repte ISBI 2012 Segmentació d'estructures neuronals en
   piles de microscòpia electrònica.^[35] Aquestes xarxes neuronals també
   van ser els primers reconeixedors de patrons artificials que van
   aconseguir un rendiment humà competitiu o fins i tot sobrehumà^[36] en
   punts de referència com el reconeixement de senyals de trànsit (IJCNN
   2012) o el problema de dígits manuscrits del MNIST de Yann LeCun i els
   seus col·legues de la Universitat de Nova York.

Vegeu també

   [modifica]
     * Ciència cognitiva
     * Visió artificial
     * Algorisme genètic
     * Memristor

Referències

   [modifica]
    1. ↑ Hopfield, J. J. Proc. Natl. Acad. Sci. U.S.A., 79, 8, 1982,
       pàg. 2554–2558. Bibcode: 1982PNAS...79.2554H. DOI:
       10.1073/pnas.79.8.2554. PMC: 346238. PMID: 6953413.
    2. ↑ «Neural Net or Neural Network - Gartner IT Glossary».
       www.gartner.com.
    3. ↑ Arbib, p.666
    4. ↑ ^4,0 ^4,1 ^4,2 Bain. Mind and Body: The Theories of Their
       Relation. Nova York: D. Appleton and Company, 1873.
    5. ↑ ^5,0 ^5,1 James. The Principles of Psychology. Nova York: H. Holt
       and Company, 1890.
    6. ↑ Cuntz, Hermann PLOS Computational Biology, 6, 8, 2010,
       pàg. ev06.i08. DOI: 10.1371/image.pcbi.v06.i08 [Consulta: free].
    7. ↑ Sherrington, C.S. Proceedings of the Royal Society of London,
       190, 1898, pàg. 45–186. DOI: 10.1098/rstb.1898.0002 [Consulta:
       free].
    8. ↑ McCulloch, Warren; Walter Pitts Bulletin of Mathematical
       Biophysics, 5, 4, 1943, pàg. 115–133. DOI: 10.1007/BF02478259.
    9. ↑ Hebb, Donald. The Organization of Behavior. Nova York: Wiley,
       1949.
   10. ↑ Farley, B.; W.A. Clark IRE Transactions on Information Theory, 4,
       4, 1954, pàg. 76–84. DOI: 10.1109/TIT.1954.1057468.
   11. ↑ Rochester, N.; J.H. Holland, L.H. Habit and W.L. Duda IRE
       Transactions on Information Theory, 2, 3, 1956, pàg. 80–93. DOI:
       10.1109/TIT.1956.1056810.
   12. ↑ Rosenblatt, F. Psychological Review, 65, 6, 1958, pàg. 386–408.
       DOI: 10.1037/h0042519. PMID: 13602029.
   13. ↑ ^13,0 ^13,1 Werbos, P.J.. Beyond Regression: New Tools for
       Prediction and Analysis in the Behavioral Sciences, 1975.
   14. ↑ Minsky, M. An Introduction to Computational Geometry. MIT Press,
       1969. ISBN 978-0-262-63022-1.
   15. ↑ Rumelhart, D.E.. Parallel Distributed Processing: Explorations in
       the Microstructure of Cognition. Cambridge: MIT Press, 1986.
   16. ↑ Russell, Ingrid. «Neural Networks Module». Arxivat de l'original
       el 29 maig 2014. [Consulta: 2012].
   17. ↑ McCulloch, Warren; Pitts, Walter Bulletin of Mathematical
       Biophysics, 5, 4, 1943, pàg. 115–133. DOI: 10.1007/BF02478259.
   18. ↑ Copeland. The Essential Turing. Oxford University Press, 2004,
       p. 403. ISBN 978-0-19-825080-7.
   19. ↑ ^19,0 ^19,1 Billings, S. A.. Nonlinear System Identification:
       NARMAX Methods in the Time, Frequency, and Spatio-Temporal Domains.
       Wiley, 2013. ISBN 978-1-119-94359-4.
   20. ↑ Wieczorek, Szymon; Filipiak, Dominik; Filipowska, Agata Studies
       on the Semantic Web, 36, Emerging Topics in Semantic Technologies,
       2018. DOI: 10.3233/978-1-61499-894-5-179.
   21. ↑ «Neuroscientists demonstrate how to improve communication between
       different regions of the brain» (en anglès). [Consulta: 6 setembre
       2020].
   22. ↑ Rezaei, Hedyeh; Aertsen, Ad; Kumar, Arvind; Valizadeh, Alireza
       (en anglès) PLOS Computational Biology, 16, 8, 10-08-2020,
       pàg. e1008033. DOI: 10.1371/journal.pcbi.1008033. ISSN: 1553-7358.
       PMID: 32776924 [Consulta: free]. [60px-CC_BY_icon.svg.png] Text and
       images are available under a Creative Commons Attribution 4.0
       International License.
   23. ↑ Administrator, NASA. «Dryden Flight Research Center - News Room:
       News Releases: NASA NEURAL NETWORK PROJECT PASSES MILESTONE». NASA,
       05-06-2013.
   24. ↑ «Roger Bridgman's defence of neural networks». Arxivat de
       l'original el 19 març 2012. [Consulta: 1r agost 2006].
   25. ↑ «Scaling Learning Algorithms towards {AI} - LISA - Publications -
       Aigaion 2.0». www.iro.umontreal.ca.
   26. ↑ Yang, J. J.; Pickett, M. D.; Li, X. M.; Ohlberg, D. A. A.;
       Stewart, D. R.; 1 Nat. Nanotechnol., 3, 7, 2008, pàg. 429–433. DOI:
       10.1038/nnano.2008.160. PMID: 18654568.
   27. ↑ Strukov, D. B.; Snider, G. S.; Stewart, D. R.; Williams, R. S.; 1
       Nature, 453, 7191, 2008, pàg. 80–83. Bibcode: 2008Natur.453...80S.
       DOI: 10.1038/nature06932. PMID: 18451858.
   28. ↑ «2012 Kurzweil AI Interview with Jürgen Schmidhuber on the eight
       competitions won by his Deep Learning team 2009–2012». Arxivat de
       l'original el 31 agost 2018. [Consulta: 10 desembre 2012].
   29. ↑ Graves, Alex. «Offline Handwriting Recognition with
       Multidimensional Recurrent Neural Networks». A: Bengio. Advances in
       Neural Information Processing Systems 21 (NIPS'21). Neural
       Information Processing Systems (NIPS) Foundation, 2008,
       p. 545–552.
   30. ↑ Graves, A.; Liwicki, M.; Fernandez, S.; Bertolami, R.; Bunke, H.
       IEEE Transactions on Pattern Analysis and Machine Intelligence, 31,
       5, 2009, pàg. 855–868. DOI: 10.1109/TPAMI.2008.137. PMID: 19299860.
   31. ↑ Hinton, G. E.; Osindero, S.; Teh, Y. Neural Computation, 18, 7,
       2006, pàg. 1527–1554. DOI: 10.1162/neco.2006.18.7.1527. PMID:
       16764513.
   32. ↑ Fukushima, K. Biological Cybernetics, 36, 4, 1980, pàg. 93–202.
       DOI: 10.1007/BF00344251. PMID: 7370364.
   33. ↑ Riesenhuber, M.; Poggio, T. Nature Neuroscience, 2, 11, 1999,
       pàg. 1019–1025. DOI: 10.1038/14819. PMID: 10526343.
   34. ↑ D. C. Ciresan, U. Meier, J. Masci, J. Schmidhuber. Multi-Column
       Deep Neural Network for Traffic Sign Classification Arxivat
       2020-10-26 a Wayback Machine.. Neural Networks, 2012.
   35. ↑ D. Ciresan, A. Giusti, L. Gambardella, J. Schmidhuber. Deep
       Neural Networks Segment Neuronal Membranes in Electron Microscopy
       Images. In Advances in Neural Information Processing Systems (NIPS
       2012), Lake Tahoe, 2012.
   36. ↑ D. C. Ciresan, U. Meier, J. Schmidhuber. Multi-column Deep Neural
       Networks for Image Classification. IEEE Conf. on Computer Vision
       and Pattern Recognition CVPR 2012.

Enllaços externs

   [modifica]
     * A Brief Introduction to Neural Networks (D. Kriesel) - Illustrated,
       bilingual manuscript about artificial neural networks; Topics so
       far: Perceptrons, Backpropagation, Radial Basis Functions,
       Recurrent Neural Networks, Self Organizing Maps, Hopfield Networks.
       (anglès)
     * Review of Neural Networks in Materials Science

   (anglès)
   Obtingut de
   «https://ca.wikipedia.org/w/index.php?title=Xarxa_neuronal&oldid=362719
   33»
   Categories:
     * Intel·ligència artificial
     * Xarxes
     * Xarxes neuronals artificials

   Categoria oculta:
     * Articles amb la plantilla Webarchive amb enllaç wayback

     * La pàgina va ser modificada per darrera vegada el 4 oct 2025 a les
       17:02.
     * El text està disponible sota la Llicència de Creative Commons
       Reconeixement i Compartir-Igual; es poden aplicar termes
       addicionals. Vegeu les Condicions d'ús. Wikipedia® (Viquipèdia™) és
       una marca registrada de Wikimedia Foundation, Inc.

     * Política de privadesa
     * Quant al projecte Viquipèdia
     * Descàrrec de responsabilitat
     * Codi de conducta
     * Desenvolupadors
     * Estadístiques
     * Declaració de cookies
     * Versió per a mòbils

     * Wikimedia Foundation
     * Powered by MediaWiki

   (BUTTON) Cerca
   ____________________
   (BUTTON) Cerca

   [ ] Commuta la taula de continguts.
   Xarxa neuronal
   (BUTTON) 22 llengües Afegeix un tema
